{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse, os, shutil, time, warnings\n",
    "\n",
    "from fp16util import *\n",
    "from resnet import *\n",
    "from PIL import Image\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(), help='Directory to save logs and models.')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--phases', default='[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]', type=str,\n",
    "                    help='Should be a string formatted like this: [(start_lr,end_lr,num_epochs),(phase2...)]')\n",
    "    parser.add_argument('--verbose', action='store_true', help='Verbose logging')\n",
    "#     parser.add_argument('--init-bn0', action='store_true', help='Intialize running batch norm mean to 0')\n",
    "    parser.add_argument('--print-freq', '-p', default=200, type=int,\n",
    "                        metavar='N', help='print every this many steps (default: 5)')\n",
    "#     parser.add_argument('--no-bn-wd', action='store_true', help='Remove batch norm from weight decay')\n",
    "    parser.add_argument('--full-precision', action='store_true', help='Run model full precision mode. Default fp16')\n",
    "    parser.add_argument('--loss-scale', type=float, default=512,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--world-size', default=-1, type=int, \n",
    "                        help='total number of processes (machines*gpus)')\n",
    "    parser.add_argument('--scale-lr', type=float, default=1, help='You should learning rate propotionally to world size')\n",
    "    parser.add_argument('--dist-url', default='env://', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    str(Path.home()/'data/cifar10/'),\n",
    "    '--phases', '[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]',\n",
    "#     '--phases', '[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]'\n",
    "#     '--full-precision'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "args = get_parser().parse_args(args_input)\n",
    "if args.full_precision: args.loss_scale = 1\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "class PreActBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size, bs, val_bs=None):\n",
    "    os.makedirs(data_path,exist_ok=True)\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.24703,0.24349,0.26159))]\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=(args.local_rank==0), transform=train_tfms)\n",
    "    val_dataset  = datasets.CIFAR10(root=data_path, train=False, download=(args.local_rank==0), transform=val_tfms)\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "    # val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None)\n",
    "    val_sampler = None\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=val_sampler)\n",
    "    \n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler():\n",
    "    def __init__(self, optimizer, phases=[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_lr = None\n",
    "        self.phases = phases\n",
    "        self.tot_epochs = sum([p[2] for p in phases])\n",
    "\n",
    "    def linear_lr(self, start_lr, end_lr, epoch_curr, batch_curr, epoch_tot, batch_tot):\n",
    "        if args.scale_lr != 1:\n",
    "            start_lr *= args.scale_lr\n",
    "            end_lr *= args.scale_lr\n",
    "        step_tot = epoch_tot * batch_tot\n",
    "        step_curr = epoch_curr * batch_tot + batch_curr\n",
    "        step_size = (end_lr - start_lr)/step_tot\n",
    "        return start_lr + step_curr * step_size\n",
    "    \n",
    "    def get_current_phase(self, epoch):\n",
    "        epoch_accum = 0\n",
    "        for phase in self.phases:\n",
    "            start_lr,end_lr,num_epochs = phase\n",
    "            if epoch <= epoch_accum+num_epochs: return start_lr, end_lr, num_epochs, epoch - epoch_accum\n",
    "            epoch_accum += num_epochs\n",
    "        raise Exception('Epoch out of range')\n",
    "            \n",
    "    def get_lr(self, epoch, batch_curr, batch_tot):\n",
    "        start_lr, end_lr, num_epochs, relative_epoch = self.get_current_phase(epoch)\n",
    "        return self.linear_lr(start_lr, end_lr, relative_epoch, batch_curr, num_epochs, batch_tot)\n",
    "\n",
    "    def update_lr(self, epoch, batch_num, batch_tot):\n",
    "        lr = self.get_lr(epoch, batch_num, batch_tot)\n",
    "        if args.verbose and (self.current_lr != lr) and ((batch_num == 1) or (batch_num == batch_tot)): \n",
    "            print(f'Changing LR from {self.current_lr} to {lr}')\n",
    "\n",
    "        self.current_lr = lr\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr_old = param_group['lr'] or lr\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if isinstance(t, float): return t\n",
    "    if isinstance(t, int): return t\n",
    "    if hasattr(t, 'item'): return t.item()\n",
    "    else: return t[0]\n",
    "\n",
    "def train(trn_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    st = time.time()\n",
    "    trn_len = len(trn_loader)\n",
    "\n",
    "    # print('Begin training loop:', st)\n",
    "    for i,(input,target) in enumerate(trn_loader):\n",
    "        batch_size = input.size(0)\n",
    "        batch_num = i+1\n",
    "        \n",
    "        # measure data loading time\n",
    "        scheduler.update_lr(epoch, i+1, trn_len)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.distributed:\n",
    "            # Must keep track of global batch size, since not all machines are guaranteed equal batches at the end of an epoch\n",
    "            corr1 = correct(output.data, target)[0]\n",
    "            metrics = torch.tensor([batch_size, loss, corr1]).float().cuda()\n",
    "            batch_total, reduced_loss, corr1 = sum_tensor(metrics)\n",
    "            reduced_loss = reduced_loss/dist.get_world_size()\n",
    "            prec1 = corr1*(100.0/batch_total)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "            batch_total = input.size(0)\n",
    "            prec1 = accuracy(output.data, target)[0] # measure accuracy and record loss\n",
    "        losses.update(to_python_float(reduced_loss), to_python_float(batch_total))\n",
    "        top1.update(to_python_float(prec1), to_python_float(batch_total))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        if args.full_precision:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            model_grads_to_master_grads(model_params, master_params)\n",
    "            for param in master_params:\n",
    "                param.grad.data = param.grad.data/args.loss_scale\n",
    "            optimizer.step()\n",
    "            master_params_to_model_params(model_params, master_params)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==trn_len)\n",
    "        if should_print: log_batch(epoch, batch_num, trn_len, batch_time, losses, top1)\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_len = len(val_loader)\n",
    "\n",
    "    for i,(input,target) in enumerate(val_loader):\n",
    "        batch_num = i+1\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target).data\n",
    "        batch_total = input.size(0)\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "            \n",
    "        losses.update(to_python_float(loss), batch_total)\n",
    "        top1.update(to_python_float(prec1), batch_total)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==val_len)\n",
    "        if should_print: log_batch(epoch, batch_num, val_len, batch_time, losses, top1)\n",
    "            \n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def log_batch(epoch, batch_num, batch_len, batch_time, loss, top1):\n",
    "    if args.local_rank==0 and args.verbose:\n",
    "        output = ('Epoch: [{0}][{1}/{2}]\\t' \\\n",
    "                + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})').format(\n",
    "                epoch, batch_num, batch_len, batch_time=batch_time, loss=loss, top1=top1)\n",
    "        print(output)\n",
    "        with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "            f.write(output + '\\n')\n",
    "            \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = self.avg = self.sum = self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    corrrect_ks = correct(output, target, topk)\n",
    "    batch_size = target.size(0)\n",
    "    return [correct_k.float().mul_(100.0 / batch_size) for correct_k in corrrect_ks]\n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sum_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    return rt\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out batch norm parameters and remove them from weight decay - gets us higher accuracy 93.2 -> 93.48\n",
    "# https://arxiv.org/pdf/1807.11205.pdf\n",
    "def bnwd_optim_params(model, model_params, master_params):\n",
    "    bn_params, remaining_params = split_bn_params(model, model_params, master_params)\n",
    "    return [{'params':bn_params,'weight_decay':0}, {'params':remaining_params}]\n",
    "\n",
    "\n",
    "def split_bn_params(model, model_params, master_params):\n",
    "    def get_bn_params(module):\n",
    "        if isinstance(module, torch.nn.modules.batchnorm._BatchNorm): return module.parameters()\n",
    "        accum = set()\n",
    "        for child in module.children(): [accum.add(p) for p in get_bn_params(child)]\n",
    "        return accum\n",
    "    \n",
    "    mod_bn_params = get_bn_params(model)\n",
    "    zipped_params = list(zip(model_params, master_params))\n",
    "\n",
    "    mas_bn_params = [p_mast for p_mod,p_mast in zipped_params if p_mod in mod_bn_params]\n",
    "    mas_rem_params = [p_mast for p_mod,p_mast in zipped_params if p_mod not in mod_bn_params]\n",
    "    return mas_bn_params, mas_rem_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own implementation of lars\n",
    "class LARS(torch.optim.Optimizer):\n",
    "    # SGD https://raw.githubusercontent.com/pytorch/pytorch/master/torch/optim/sgd.py\n",
    "    # η (eta) = \"trust\" coefficient\n",
    "    def __init__(self, params, lr, momentum=0, dampening=0,\n",
    "                 weight_decay=0, nesterov=False, eta=0.02, eps=1e-8, lars=True, local_mult=1):\n",
    "        self.lr = lr\n",
    "        self.lars = True\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
    "                        weight_decay=weight_decay, nesterov=nesterov, eta=eta)\n",
    "        if nesterov and (momentum <= 0 or dampening != 0):\n",
    "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
    "        self.local_mult = 1\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        if self.local_mult <= 0: self.lars = False\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "            eta = group['eta']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "                if self.lars: local_lr = eta * torch.norm(p.data) / torch.norm(d_p)\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                        buf.mul_(momentum).add_(d_p)\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
    "                    if nesterov:\n",
    "                        d_p = d_p.add(momentum, buf)\n",
    "                    else:\n",
    "                        d_p = buf\n",
    "                # print('Learning rate:', local_lr, local_lr*group['lr'])\n",
    "                if self.lars: ratio = (1 - local_lr) * (1 - self.local_mult) + local_lr\n",
    "                if self.lars: p.data.add_(-min(ratio*group['lr'], group['lr']), d_p)\n",
    "                else: p.data.add_(-group['lr'], d_p)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t33\t\t0.2156\t\t1.9826\t\t2.3933\t\t16.74\n",
      "1\t\t33\t\t0.4323\t\t1.4413\t\t1.5176\t\t47.87\n",
      "2\t\t33\t\t0.6492\t\t1.1644\t\t1.5214\t\t50.57\n",
      "3\t\t33\t\t0.8688\t\t0.9453\t\t1.3104\t\t56.48\n",
      "4\t\t33\t\t1.0902\t\t0.7748\t\t0.9202\t\t68.08\n",
      "5\t\t33\t\t1.3072\t\t0.668\t\t0.7514\t\t75.12\n",
      "6\t\t33\t\t1.5251\t\t0.5829\t\t0.9944\t\t68.46\n",
      "7\t\t33\t\t1.7431\t\t0.5426\t\t1.2325\t\t63.33\n",
      "8\t\t33\t\t1.9636\t\t0.5058\t\t0.8011\t\t72.93\n",
      "9\t\t33\t\t2.1818\t\t0.4776\t\t1.1752\t\t64.68\n",
      "10\t\t33\t\t2.3996\t\t0.4607\t\t1.2616\t\t60.52\n",
      "11\t\t33\t\t2.6192\t\t0.4648\t\t0.9381\t\t70.35\n",
      "12\t\t33\t\t2.8375\t\t0.4556\t\t1.1569\t\t64.9\n",
      "13\t\t33\t\t3.056\t\t0.4687\t\t0.7699\t\t74.23\n",
      "14\t\t33\t\t3.2754\t\t0.4678\t\t0.6422\t\t78.97\n",
      "15\t\t33\t\t3.4939\t\t0.4879\t\t1.8656\t\t49.11\n",
      "16\t\t33\t\t3.711\t\t0.4095\t\t0.6285\t\t79.04\n",
      "17\t\t33\t\t3.9296\t\t0.3723\t\t1.9593\t\t55.65\n",
      "18\t\t33\t\t4.1495\t\t0.3512\t\t1.0149\t\t69.13\n",
      "19\t\t33\t\t4.3675\t\t0.3312\t\t0.8777\t\t72.93\n",
      "20\t\t33\t\t4.5863\t\t0.3149\t\t0.5967\t\t79.82\n",
      "21\t\t33\t\t4.8032\t\t0.289\t\t0.7231\t\t77.24\n",
      "22\t\t33\t\t5.0217\t\t0.2676\t\t0.8828\t\t72.03\n",
      "23\t\t33\t\t5.2425\t\t0.2514\t\t1.1512\t\t69.01\n",
      "24\t\t33\t\t5.4617\t\t0.2216\t\t0.4473\t\t85.04\n",
      "25\t\t33\t\t5.68\t\t0.1981\t\t0.4104\t\t85.86\n",
      "26\t\t33\t\t5.9002\t\t0.1774\t\t0.3649\t\t88.03\n",
      "27\t\t33\t\t6.1191\t\t0.1458\t\t0.3602\t\t88.02\n",
      "28\t\t33\t\t6.342\t\t0.1192\t\t0.3314\t\t89.45\n",
      "29\t\t33\t\t6.5608\t\t0.0904\t\t0.2595\t\t91.58\n",
      "30\t\t33\t\t6.7782\t\t0.0651\t\t0.2338\t\t92.55\n",
      "31\t\t33\t\t7.001\t\t0.0606\t\t0.2297\t\t92.71\n",
      "32\t\t33\t\t7.2183\t\t0.054\t\t0.2323\t\t92.92\n",
      "33\t\t33\t\t7.4373\t\t0.0468\t\t0.2262\t\t93.07\n",
      "34\t\t33\t\t7.655\t\t0.0438\t\t0.2299\t\t93.1\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "scale = 6\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-4*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t33\t\t0.2845\t\t1.9879\t\t2.6688\t\t16.75\n",
      "1\t\t33\t\t0.499\t\t1.4477\t\t1.668\t\t41.04\n",
      "2\t\t33\t\t0.7137\t\t1.1732\t\t1.5731\t\t49.24\n",
      "3\t\t33\t\t0.9286\t\t0.9529\t\t1.5037\t\t57.04\n",
      "4\t\t33\t\t1.1452\t\t0.7878\t\t1.0973\t\t65.45\n",
      "5\t\t33\t\t1.3622\t\t0.6538\t\t0.8876\t\t71.79\n",
      "6\t\t33\t\t1.5788\t\t0.5832\t\t1.7367\t\t56.79\n",
      "7\t\t33\t\t1.8001\t\t0.5408\t\t0.8762\t\t72.98\n",
      "8\t\t33\t\t2.0175\t\t0.502\t\t0.787\t\t73.66\n",
      "9\t\t33\t\t2.2344\t\t0.4866\t\t1.2111\t\t62.56\n",
      "10\t\t33\t\t2.4491\t\t0.4803\t\t1.0012\t\t67.35\n",
      "11\t\t33\t\t2.6658\t\t0.4654\t\t1.172\t\t64.57\n",
      "12\t\t33\t\t2.883\t\t0.4601\t\t1.1078\t\t64.72\n",
      "13\t\t33\t\t3.0885\t\tnan\t\tnan\t\t0.37\n",
      "14\t\t33\t\t3.2914\t\tnan\t\tnan\t\t0.37\n",
      "15\t\t33\t\t3.4944\t\tnan\t\tnan\t\t0.37\n",
      "16\t\t33\t\t3.7\t\tnan\t\tnan\t\t0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-275:\n",
      "Process Process-273:\n",
      "Process Process-276:\n",
      "Process Process-278:\n",
      "Process Process-277:\n",
      "Process Process-274:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-279:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-280:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = Image.fromarray(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2450, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2403, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 448, in __call__\n",
      "    return F.hflip(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2446, in fromarray\n",
      "    obj = obj.tobytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 347, in hflip\n",
      "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1297, in pad\n",
      "    if not np.asarray(pad_width).dtype.kind == 'i':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-805792b2015b>\", line 43, in <module>\n",
      "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
      "  File \"<ipython-input-8-7d0ced679dc0>\", line 21, in train\n",
      "    for i,(input,target) in enumerate(trn_loader):\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 66, in __iter__\n",
      "    self.preload()\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 54, in preload\n",
      "    self.next_input, self.next_target = next(self.loaditer)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 280, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 259, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 24648) exited unexpectedly with exit code 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "SystemError: <built-in function _error_if_any_worker_fails> returned a result with an error set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2335, in frombytes\n",
      "    im = new(mode, size)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2299, in new\n",
      "    return Image()._new(core.fill(mode, size, color))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/numeric.py\", line 492, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2201, in transpose\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1080, in _validate_lengths\n",
      "    normshp = _normalize_shape(narray, number_elements)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1043, in _normalize_shape\n",
      "    shape_arr = np.round(shape_arr).astype(int)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 828, in load\n",
      "    return self.im.pixel_access(self.readonly)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1446, in pad\n",
      "    newmat = _pad_ref(newmat, (pad_before, pad_after), method, axis)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = Image.fromarray(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2450, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 2851, in round_\n",
      "    return around(a, decimals=decimals, out=out)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2345, in frombuffer\n",
      "    def frombuffer(mode, size, data, decoder_name=\"raw\", *args):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "scale = 6\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-4*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))\n",
    "    if epoch == 12: optimizer.lars = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=False, local_rank=0, loss_scale=512, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t33\t\t0.1903\t\t1.9546\t\t1.7348\t\t35.04\n",
      "1\t\t33\t\t0.3061\t\t1.6089\t\t2.6223\t\t32.54\n",
      "2\t\t33\t\t0.4266\t\t1.4725\t\t1.5662\t\t49.81\n",
      "3\t\t33\t\t0.5437\t\t1.0646\t\t1.2858\t\t56.45\n",
      "4\t\t33\t\t0.6615\t\t0.8873\t\t1.8105\t\t49.52\n",
      "5\t\t33\t\t0.7811\t\t0.7554\t\t1.0411\t\t65.34\n",
      "6\t\t33\t\t0.8974\t\t0.6541\t\t0.9821\t\t66.13\n",
      "7\t\t33\t\t1.0139\t\t0.5803\t\t1.2272\t\t58.83\n",
      "8\t\t33\t\t1.1318\t\t0.6226\t\t0.8307\t\t73.61\n",
      "9\t\t33\t\t1.2491\t\t0.5344\t\t1.082\t\t66.34\n",
      "10\t\t33\t\t1.3671\t\t0.4943\t\t0.8002\t\t73.18\n",
      "11\t\t33\t\t1.4879\t\t0.4836\t\t2.1068\t\t52.28\n",
      "12\t\t33\t\t1.6045\t\t0.9523\t\tnan\t\t10.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-209:\n",
      "Process Process-210:\n",
      "Process Process-212:\n",
      "Process Process-215:\n",
      "Process Process-216:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Exception in thread Thread-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 71, in _worker_manager_loop\n",
      "    r = in_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-ebfb043e484a>\", line 43, in <module>\n",
      "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
      "  File \"<ipython-input-8-7d0ced679dc0>\", line 61, in train\n",
      "    torch.cuda.synchronize()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 339, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 27160) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-213:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-214:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = Image.fromarray(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Process Process-211:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2446, in fromarray\n",
      "    obj = obj.tobytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 78, in to_tensor\n",
      "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 83, in to_tensor\n",
      "    return img.float().div(255)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1080, in _validate_lengths\n",
      "    normshp = _normalize_shape(narray, number_elements)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 83, in to_tensor\n",
      "    return img.float().div(255)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = Image.fromarray(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2450, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1036, in _normalize_shape\n",
      "    shape_arr = np.broadcast_to(shape_arr, (ndims, 2))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\", line 173, in broadcast_to\n",
      "    return _broadcast_to(array, shape, subok=subok, readonly=True)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2403, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\", line 128, in _broadcast_to\n",
      "    op_flags=[op_flag], itershape=shape, order='C').itviews[0]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2335, in frombytes\n",
      "    im = new(mode, size)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2299, in new\n",
      "    return Image()._new(core.fill(mode, size, color))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 546, in _new\n",
      "    if im.mode in ('P', 'PA'):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "# args.full_precision = True\n",
    "# args.loss_scale = 1\n",
    "scale = 6\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = torch.optim.SGD(optim_params, lr=0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.01, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-3*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.full_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=False, local_rank=0, loss_scale=512, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t49\t\t0.1402\t\t1.8387\t\t1.4589\t\t46.45\n",
      "1\t\t49\t\t0.2551\t\t1.4007\t\t1.4751\t\t50.81\n",
      "2\t\t49\t\t0.3712\t\t1.0809\t\t1.6705\t\t55.14\n",
      "3\t\t49\t\t0.4873\t\t0.879\t\t1.2832\t\t62.21\n",
      "4\t\t49\t\t0.6022\t\t0.6939\t\t0.7004\t\t75.96\n",
      "5\t\t49\t\t0.7185\t\t0.5765\t\t0.7336\t\t74.56\n",
      "6\t\t49\t\t0.8339\t\t0.5234\t\t0.5688\t\t80.19\n",
      "7\t\t49\t\t0.9498\t\t0.4719\t\t0.7415\t\t74.84\n",
      "8\t\t49\t\t1.0675\t\t0.4436\t\t0.717\t\t76.61\n",
      "9\t\t49\t\t1.1844\t\t0.4225\t\t0.7966\t\t72.42\n",
      "10\t\t49\t\t1.3005\t\t0.4355\t\t1.0771\t\t67.29\n",
      "11\t\t49\t\t1.4161\t\t0.4032\t\t0.7548\t\t74.76\n",
      "12\t\t49\t\t1.5309\t\t0.4309\t\t0.66\t\t78.4\n",
      "13\t\t49\t\t1.6458\t\t0.433\t\t0.9381\t\t71.79\n",
      "14\t\t49\t\t1.7624\t\t0.4598\t\t0.9541\t\t68.32\n",
      "15\t\t49\t\t1.8784\t\t0.6151\t\t1.8388\t\t54.6\n",
      "16\t\t49\t\t1.9945\t\t0.4754\t\t0.5538\t\t81.59\n",
      "17\t\t49\t\t2.1115\t\t0.3377\t\t0.6436\t\t78.54\n",
      "18\t\t49\t\t2.2265\t\t0.3153\t\t0.5566\t\t81.36\n",
      "19\t\t49\t\t2.3417\t\t0.2919\t\t0.5237\t\t82.63\n",
      "20\t\t49\t\t2.4581\t\t0.2722\t\t0.4041\t\t86.69\n",
      "21\t\t49\t\t2.5746\t\t0.2502\t\t0.5294\t\t82.65\n",
      "22\t\t49\t\t2.6896\t\t0.2409\t\t0.5264\t\t83.83\n",
      "23\t\t49\t\t2.8065\t\t0.2136\t\t0.4705\t\t84.78\n",
      "24\t\t49\t\t2.9206\t\t0.192\t\t0.3279\t\t89.13\n",
      "25\t\t49\t\t3.0353\t\t0.1673\t\t0.2983\t\t89.91\n",
      "26\t\t49\t\t3.1501\t\t0.1432\t\t0.3166\t\t89.77\n",
      "27\t\t49\t\t3.2625\t\t0.117\t\t0.2747\t\t91.27\n",
      "28\t\t49\t\t3.3793\t\t0.0897\t\t0.2411\t\t92.11\n",
      "29\t\t49\t\t3.4934\t\t0.0621\t\t0.2382\t\t92.58\n",
      "30\t\t49\t\t3.6074\t\t0.0439\t\t0.225\t\t93.12\n",
      "31\t\t49\t\t3.7229\t\t0.0415\t\t0.2163\t\t93.2\n",
      "32\t\t49\t\t3.8386\t\t0.0338\t\t0.2184\t\t93.45\n",
      "33\t\t49\t\t3.9561\t\t0.0314\t\t0.222\t\t93.39\n",
      "34\t\t49\t\t4.0717\t\t0.0294\t\t0.2199\t\t93.53\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "# args.full_precision = True\n",
    "# args.loss_scale = 1\n",
    "\n",
    "scale = 4\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = torch.optim.SGD(optim_params, lr=0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.01, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-3*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t49\t\t0.1249\t\t1.9059\t\t1.8281\t\t36.99\n",
      "1\t\t49\t\t0.2518\t\t1.3144\t\t1.2182\t\t55.88\n",
      "2\t\t49\t\t0.3788\t\t1.0243\t\t1.4156\t\t54.51\n",
      "3\t\t49\t\t0.5056\t\t0.8188\t\t1.0237\t\t66.64\n",
      "4\t\t49\t\t0.63\t\t0.6801\t\t1.008\t\t65.66\n",
      "5\t\t49\t\t0.7553\t\t0.5885\t\t0.6779\t\t76.97\n",
      "6\t\t49\t\t0.8643\t\tnan\t\tnan\t\t0.31\n",
      "7\t\t49\t\t0.9738\t\tnan\t\tnan\t\t0.31\n",
      "8\t\t49\t\t1.0832\t\tnan\t\tnan\t\t0.31\n",
      "9\t\t49\t\t1.1916\t\tnan\t\tnan\t\t0.31\n",
      "10\t\t49\t\t1.2996\t\tnan\t\tnan\t\t0.31\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "scale = 4\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-3*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))\n",
    "    if epoch == 5: optimizer.lars = False\n",
    "    if epoch == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t49\t\t0.2205\t\t1.931\t\t1.6546\t\t39.43\n",
      "Lars: True\n",
      "local mult: 1.0\n",
      "1\t\t49\t\t0.4415\t\t1.2995\t\t1.183\t\t56.39\n",
      "Lars: True\n",
      "local mult: 0.8\n",
      "2\t\t49\t\t0.6603\t\t1.232\t\t1.1762\t\t58.05\n",
      "Lars: True\n",
      "local mult: 0.6\n",
      "3\t\t49\t\t0.8812\t\t0.9543\t\t1.1389\t\t63.47\n",
      "Lars: True\n",
      "local mult: 0.4\n",
      "4\t\t49\t\t1.1012\t\t0.9376\t\t0.8431\t\t72.18\n",
      "Lars: True\n",
      "local mult: 0.2\n",
      "5\t\t49\t\t1.3217\t\t0.6632\t\t0.9176\t\t69.67\n",
      "Lars: True\n",
      "local mult: 0.0\n",
      "6\t\t49\t\t1.5263\t\t0.6041\t\t0.5563\t\t81.07\n",
      "Lars: False\n",
      "local mult: 0\n",
      "7\t\t49\t\t1.7317\t\t0.5003\t\t0.7659\t\t74.32\n",
      "Lars: False\n",
      "local mult: 0\n",
      "8\t\t49\t\t1.9391\t\t0.4577\t\t0.7224\t\t75.22\n",
      "Lars: False\n",
      "local mult: 0\n",
      "9\t\t49\t\t2.1469\t\t0.4429\t\t0.8354\t\t71.83\n",
      "Lars: False\n",
      "local mult: 0\n",
      "10\t\t49\t\t2.3533\t\t0.4453\t\t0.9068\t\t69.68\n",
      "Lars: False\n",
      "local mult: 0\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "scale = 4\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-3*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "wean = 5.0\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))\n",
    "#     if epoch == 5: optimizer.lars = False\n",
    "    optimizer.local_mult = max((wean - epoch)/wean, 0)\n",
    "    print('Lars:', optimizer.lars)\n",
    "    print('local mult:', optimizer.local_mult)\n",
    "    if epoch == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t33\t\t0.2847\t\t1.9737\t\t2.2577\t\t20.57\n",
      "1\t\t33\t\t0.5009\t\t1.4178\t\t1.49\t\t49.22\n",
      "2\t\t33\t\t0.7209\t\t1.11\t\t1.1421\t\t60.39\n",
      "3\t\t33\t\t0.9404\t\t0.9082\t\t1.3624\t\t57.56\n",
      "4\t\t33\t\t1.159\t\t0.7457\t\t0.8396\t\t71.72\n",
      "5\t\t33\t\t1.3783\t\t0.6476\t\t1.5352\t\t57.22\n",
      "6\t\t33\t\t1.5963\t\t0.5787\t\t0.7353\t\t74.82\n",
      "7\t\t33\t\t1.8164\t\t0.5222\t\t0.8139\t\t73.37\n",
      "8\t\t33\t\t2.0366\t\t0.497\t\t0.8971\t\t70.06\n",
      "9\t\t33\t\t2.2599\t\t0.4817\t\t0.7581\t\t74.1\n",
      "10\t\t33\t\t2.4815\t\t0.461\t\t1.1255\t\t66.84\n",
      "11\t\t33\t\t2.7003\t\t0.4516\t\t0.8122\t\t72.06\n",
      "12\t\t33\t\t2.9201\t\t0.464\t\t0.9269\t\t69.47\n",
      "13\t\t33\t\t3.1424\t\t0.4524\t\t2.5753\t\t48.24\n",
      "14\t\t33\t\t3.3632\t\t0.4709\t\t1.7031\t\t59.64\n",
      "15\t\t33\t\t3.5874\t\t0.4853\t\t2.0482\t\t52.93\n",
      "Lars: True\n",
      "local mult: 1.0\n",
      "16\t\t33\t\t3.8085\t\t0.4078\t\t0.9592\t\t67.86\n",
      "Lars: True\n",
      "local mult: 0.8333333333333334\n",
      "17\t\t33\t\t4.0289\t\t0.3947\t\t0.6368\t\t77.5\n",
      "Lars: True\n",
      "local mult: 0.6666666666666666\n",
      "18\t\t33\t\t4.2497\t\t0.3622\t\t0.9336\t\t72.64\n",
      "Lars: True\n",
      "local mult: 0.5\n",
      "19\t\t33\t\t4.4728\t\t0.3494\t\t0.6003\t\t80.2\n",
      "Lars: True\n",
      "local mult: 0.3333333333333333\n",
      "20\t\t33\t\t4.6971\t\t0.3168\t\t0.9111\t\t74.66\n",
      "Lars: True\n",
      "local mult: 0.16666666666666666\n",
      "21\t\t33\t\t4.9169\t\t0.2902\t\t0.4813\t\t84.26\n",
      "Lars: True\n",
      "local mult: 0.0\n",
      "22\t\t33\t\t5.1276\t\t0.265\t\t0.6958\t\t80.11\n",
      "Lars: False\n",
      "local mult: 0\n",
      "23\t\t33\t\t5.337\t\t0.2382\t\t0.4168\t\t86.33\n",
      "Lars: False\n",
      "local mult: 0\n",
      "24\t\t33\t\t5.5462\t\t0.2115\t\t0.703\t\t78.96\n",
      "Lars: False\n",
      "local mult: 0\n",
      "25\t\t33\t\t5.7549\t\t0.189\t\t0.4187\t\t86.08\n",
      "Lars: False\n",
      "local mult: 0\n",
      "26\t\t33\t\t5.9665\t\t0.1587\t\t0.3925\t\t87.05\n",
      "Lars: False\n",
      "local mult: 0\n",
      "27\t\t33\t\t6.1802\t\t0.1321\t\t0.37\t\t88.67\n",
      "Lars: False\n",
      "local mult: 0\n",
      "28\t\t33\t\t6.3939\t\t0.1031\t\t0.3292\t\t89.99\n",
      "Lars: False\n",
      "local mult: 0\n",
      "29\t\t33\t\t6.6048\t\t0.0778\t\t0.2404\t\t92.54\n",
      "Lars: False\n",
      "local mult: 0\n",
      "30\t\t33\t\t6.8147\t\t0.0558\t\t0.2407\t\t93.03\n",
      "Lars: False\n",
      "local mult: 0\n",
      "31\t\t33\t\t7.0252\t\t0.0509\t\t0.2353\t\t93.09\n",
      "Lars: False\n",
      "local mult: 0\n",
      "32\t\t33\t\t7.2346\t\t0.0429\t\t0.2354\t\t93.23\n",
      "Lars: False\n",
      "local mult: 0\n",
      "33\t\t33\t\t7.4481\t\t0.0397\t\t0.2397\t\t93.34\n",
      "Lars: False\n",
      "local mult: 0\n",
      "34\t\t33\t\t7.6594\t\t0.037\t\t0.2368\t\t93.47\n",
      "Lars: False\n",
      "local mult: 0\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "scale = 6\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(1e-3*scale,2e-1*scale,15),(2e-1*scale,1e-2*scale,15),(1e-2*scale,0,5)])\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 256*scale, 256*scale)\n",
    "\n",
    "wean = 10.0\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))\n",
    "#     if epoch == 5: optimizer.lars = False\n",
    "    if epoch >= 15:\n",
    "        optimizer.local_mult = max((21 - epoch)/(6), 0)\n",
    "        print('Lars:', optimizer.lars)\n",
    "        print('local mult:', optimizer.local_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
