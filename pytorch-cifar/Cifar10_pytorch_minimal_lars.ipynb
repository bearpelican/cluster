{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse, os, shutil, time, warnings\n",
    "\n",
    "from fp16util import *\n",
    "from resnet import *\n",
    "from PIL import Image\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(), help='Directory to save logs and models.')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--phases', default='[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]', type=str,\n",
    "                    help='Should be a string formatted like this: [(start_lr,end_lr,num_epochs),(phase2...)]')\n",
    "    parser.add_argument('--verbose', action='store_true', help='Verbose logging')\n",
    "#     parser.add_argument('--init-bn0', action='store_true', help='Intialize running batch norm mean to 0')\n",
    "    parser.add_argument('--print-freq', '-p', default=200, type=int,\n",
    "                        metavar='N', help='print every this many steps (default: 5)')\n",
    "#     parser.add_argument('--no-bn-wd', action='store_true', help='Remove batch norm from weight decay')\n",
    "    parser.add_argument('--full-precision', action='store_true', help='Run model full precision mode. Default fp16')\n",
    "    parser.add_argument('--loss-scale', type=float, default=512,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--world-size', default=-1, type=int, \n",
    "                        help='total number of processes (machines*gpus)')\n",
    "    parser.add_argument('--scale-lr', type=float, default=1, help='You should learning rate propotionally to world size')\n",
    "    parser.add_argument('--dist-url', default='env://', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    str(Path.home()/'data/cifar10/'),\n",
    "    '--phases', '[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]',\n",
    "#     '--phases', '[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]'\n",
    "#     '--full-precision'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "args = get_parser().parse_args(args_input)\n",
    "if args.full_precision: args.loss_scale = 1\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "class PreActBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size, bs, val_bs=None):\n",
    "    os.makedirs(data_path,exist_ok=True)\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.24703,0.24349,0.26159))]\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=(args.local_rank==0), transform=train_tfms)\n",
    "    val_dataset  = datasets.CIFAR10(root=data_path, train=False, download=(args.local_rank==0), transform=val_tfms)\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "    # val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None)\n",
    "    val_sampler = None\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=val_sampler)\n",
    "    \n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler():\n",
    "    def __init__(self, optimizer, phases=[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_lr = None\n",
    "        self.phases = phases\n",
    "        self.tot_epochs = sum([p[2] for p in phases])\n",
    "\n",
    "    def linear_lr(self, start_lr, end_lr, epoch_curr, batch_curr, epoch_tot, batch_tot):\n",
    "        if args.scale_lr != 1:\n",
    "            start_lr *= args.scale_lr\n",
    "            end_lr *= args.scale_lr\n",
    "        step_tot = epoch_tot * batch_tot\n",
    "        step_curr = epoch_curr * batch_tot + batch_curr\n",
    "        step_size = (end_lr - start_lr)/step_tot\n",
    "        return start_lr + step_curr * step_size\n",
    "    \n",
    "    def get_current_phase(self, epoch):\n",
    "        epoch_accum = 0\n",
    "        for phase in self.phases:\n",
    "            start_lr,end_lr,num_epochs = phase\n",
    "            if epoch <= epoch_accum+num_epochs: return start_lr, end_lr, num_epochs, epoch - epoch_accum\n",
    "            epoch_accum += num_epochs\n",
    "        raise Exception('Epoch out of range')\n",
    "            \n",
    "    def get_lr(self, epoch, batch_curr, batch_tot):\n",
    "        start_lr, end_lr, num_epochs, relative_epoch = self.get_current_phase(epoch)\n",
    "        return self.linear_lr(start_lr, end_lr, relative_epoch, batch_curr, num_epochs, batch_tot)\n",
    "\n",
    "    def update_lr(self, epoch, batch_num, batch_tot):\n",
    "        lr = self.get_lr(epoch, batch_num, batch_tot)\n",
    "        if args.verbose and (self.current_lr != lr) and ((batch_num == 1) or (batch_num == batch_tot)): \n",
    "            print(f'Changing LR from {self.current_lr} to {lr}')\n",
    "\n",
    "        self.current_lr = lr\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr_old = param_group['lr'] or lr\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if isinstance(t, float): return t\n",
    "    if isinstance(t, int): return t\n",
    "    if hasattr(t, 'item'): return t.item()\n",
    "    else: return t[0]\n",
    "\n",
    "def train(trn_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    st = time.time()\n",
    "    trn_len = len(trn_loader)\n",
    "\n",
    "    # print('Begin training loop:', st)\n",
    "    for i,(input,target) in enumerate(trn_loader):\n",
    "        batch_size = input.size(0)\n",
    "        batch_num = i+1\n",
    "        \n",
    "        # measure data loading time\n",
    "        scheduler.update_lr(epoch, i+1, trn_len)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.distributed:\n",
    "            # Must keep track of global batch size, since not all machines are guaranteed equal batches at the end of an epoch\n",
    "            corr1 = correct(output.data, target)[0]\n",
    "            metrics = torch.tensor([batch_size, loss, corr1]).float().cuda()\n",
    "            batch_total, reduced_loss, corr1 = sum_tensor(metrics)\n",
    "            reduced_loss = reduced_loss/dist.get_world_size()\n",
    "            prec1 = corr1*(100.0/batch_total)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "            batch_total = input.size(0)\n",
    "            prec1 = accuracy(output.data, target)[0] # measure accuracy and record loss\n",
    "        losses.update(to_python_float(reduced_loss), to_python_float(batch_total))\n",
    "        top1.update(to_python_float(prec1), to_python_float(batch_total))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        if args.full_precision:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            model_grads_to_master_grads(model_params, master_params)\n",
    "            for param in master_params:\n",
    "                param.grad.data = param.grad.data/args.loss_scale\n",
    "            optimizer.step()\n",
    "            master_params_to_model_params(model_params, master_params)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==trn_len)\n",
    "        if should_print: log_batch(epoch, batch_num, trn_len, batch_time, losses, top1)\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_len = len(val_loader)\n",
    "\n",
    "    for i,(input,target) in enumerate(val_loader):\n",
    "        batch_num = i+1\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target).data\n",
    "        batch_total = input.size(0)\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "            \n",
    "        losses.update(to_python_float(loss), batch_total)\n",
    "        top1.update(to_python_float(prec1), batch_total)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==val_len)\n",
    "        if should_print: log_batch(epoch, batch_num, val_len, batch_time, losses, top1)\n",
    "            \n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def log_batch(epoch, batch_num, batch_len, batch_time, loss, top1):\n",
    "    if args.local_rank==0 and args.verbose:\n",
    "        output = ('Epoch: [{0}][{1}/{2}]\\t' \\\n",
    "                + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})').format(\n",
    "                epoch, batch_num, batch_len, batch_time=batch_time, loss=loss, top1=top1)\n",
    "        print(output)\n",
    "        with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "            f.write(output + '\\n')\n",
    "            \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = self.avg = self.sum = self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    corrrect_ks = correct(output, target, topk)\n",
    "    batch_size = target.size(0)\n",
    "    return [correct_k.float().mul_(100.0 / batch_size) for correct_k in corrrect_ks]\n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sum_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    return rt\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out batch norm parameters and remove them from weight decay - gets us higher accuracy 93.2 -> 93.48\n",
    "# https://arxiv.org/pdf/1807.11205.pdf\n",
    "def bnwd_optim_params(model, model_params, master_params):\n",
    "    bn_params, remaining_params = split_bn_params(model, model_params, master_params)\n",
    "    return [{'params':bn_params,'weight_decay':0}, {'params':remaining_params}]\n",
    "\n",
    "\n",
    "def split_bn_params(model, model_params, master_params):\n",
    "    def get_bn_params(module):\n",
    "        if isinstance(module, torch.nn.modules.batchnorm._BatchNorm): return module.parameters()\n",
    "        accum = set()\n",
    "        for child in module.children(): [accum.add(p) for p in get_bn_params(child)]\n",
    "        return accum\n",
    "    \n",
    "    mod_bn_params = get_bn_params(model)\n",
    "    zipped_params = list(zip(model_params, master_params))\n",
    "\n",
    "    mas_bn_params = [p_mast for p_mod,p_mast in zipped_params if p_mod in mod_bn_params]\n",
    "    mas_rem_params = [p_mast for p_mod,p_mast in zipped_params if p_mod not in mod_bn_params]\n",
    "    return mas_bn_params, mas_rem_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own implementation of lars\n",
    "class LARS(torch.optim.Optimizer):\n",
    "    # SGD https://raw.githubusercontent.com/pytorch/pytorch/master/torch/optim/sgd.py\n",
    "    # η (eta) = \"trust\" coefficient\n",
    "    def __init__(self, params, lr, momentum=0, dampening=0,\n",
    "                 weight_decay=0, nesterov=False, eta=0.02, eps=1e-8, lars=True):\n",
    "        self.lr = lr\n",
    "        self.lars = True\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
    "                        weight_decay=weight_decay, nesterov=nesterov, eta=eta)\n",
    "        if nesterov and (momentum <= 0 or dampening != 0):\n",
    "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "            eta = group['eta']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "                if lars: local_lr = eta * torch.norm(p.data) / torch.norm(d_p)\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                        buf.mul_(momentum).add_(d_p)\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
    "                    if nesterov:\n",
    "                        d_p = d_p.add(momentum, buf)\n",
    "                    else:\n",
    "                        d_p = buf\n",
    "                # print('Learning rate:', local_lr, local_lr*group['lr'])\n",
    "                if lars: p.data.add_(-min(local_lr*group['lr'], group['lr']), d_p)\n",
    "                else: p.data.add_(-group['lr'], d_p)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.2573\t\t1.9591\t\t1.5154\t\t44.9\n",
      "1\t\t196\t\t0.5009\t\t1.3311\t\t1.2488\t\t55.02\n",
      "2\t\t196\t\t0.7464\t\t1.0384\t\t1.2486\t\t56.42\n",
      "3\t\t196\t\t0.9902\t\t0.8468\t\t1.0063\t\t65.54\n",
      "4\t\t196\t\t1.2363\t\t0.7105\t\t1.0976\t\t64.18\n",
      "5\t\t196\t\t1.4804\t\t0.6182\t\t0.6572\t\t77.66\n",
      "6\t\t196\t\t1.7221\t\t0.5649\t\t0.9406\t\t68.91\n",
      "7\t\t196\t\t1.9676\t\t0.5214\t\t0.7907\t\t73.62\n",
      "8\t\t196\t\t2.2121\t\t0.4827\t\t0.7649\t\t74.82\n",
      "9\t\t196\t\t2.456\t\t0.4577\t\t0.7168\t\t76.67\n",
      "10\t\t196\t\t2.6996\t\t0.4391\t\t0.7836\t\t74.04\n",
      "11\t\t196\t\t2.9439\t\t0.4256\t\t0.6637\t\t77.76\n",
      "12\t\t196\t\t3.1893\t\t0.412\t\t0.5443\t\t81.44\n",
      "13\t\t196\t\t3.4343\t\t0.4069\t\t0.5543\t\t81.24\n",
      "14\t\t196\t\t3.6813\t\t0.3953\t\t0.5945\t\t79.81\n",
      "15\t\t196\t\t3.9247\t\t0.3952\t\t0.4884\t\t83.52\n",
      "16\t\t196\t\t4.1727\t\t0.361\t\t0.474\t\t84.04\n",
      "17\t\t196\t\t4.4203\t\t0.3339\t\t0.5178\t\t82.64\n",
      "18\t\t196\t\t4.665\t\t0.309\t\t0.4824\t\t84.94\n",
      "19\t\t196\t\t4.9091\t\t0.2888\t\t0.4731\t\t83.94\n",
      "20\t\t196\t\t5.1523\t\t0.2662\t\t0.4028\t\t87.04\n",
      "21\t\t196\t\t5.3979\t\t0.2409\t\t0.3944\t\t87.02\n",
      "22\t\t196\t\t5.6409\t\t0.2188\t\t0.3488\t\t88.63\n",
      "23\t\t196\t\t5.8871\t\t0.195\t\t0.3472\t\t88.97\n",
      "24\t\t196\t\t6.1331\t\t0.1741\t\t0.3259\t\t89.9\n",
      "25\t\t196\t\t6.3776\t\t0.1506\t\t0.3369\t\t89.63\n",
      "26\t\t196\t\t6.6224\t\t0.1255\t\t0.2803\t\t91.18\n",
      "27\t\t196\t\t6.8668\t\t0.1025\t\t0.2402\t\t92.6\n",
      "28\t\t196\t\t7.111\t\t0.0815\t\t0.2531\t\t92.34\n",
      "29\t\t196\t\t7.3566\t\t0.0627\t\t0.2348\t\t92.8\n",
      "30\t\t196\t\t7.5993\t\t0.0461\t\t0.2489\t\t92.65\n",
      "31\t\t196\t\t7.8434\t\t0.0464\t\t0.2416\t\t92.91\n",
      "32\t\t196\t\t8.0865\t\t0.0419\t\t0.2353\t\t93.38\n",
      "33\t\t196\t\t8.3304\t\t0.0375\t\t0.2306\t\t93.5\n",
      "34\t\t196\t\t8.5748\t\t0.0346\t\t0.2304\t\t93.59\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.2095\t\t1.7281\t\t1.6887\t\t43.98\n",
      "1\t\t196\t\t0.4187\t\t1.035\t\t1.2223\t\t59.3\n",
      "2\t\t196\t\t0.6275\t\t0.775\t\t1.0875\t\t66.09\n",
      "3\t\t196\t\t0.8374\t\t0.6364\t\t1.2896\t\t62.47\n",
      "4\t\t196\t\t1.0474\t\t0.5632\t\t0.7241\t\t76.67\n",
      "5\t\t196\t\t1.2562\t\t0.5082\t\t0.6464\t\t78.71\n",
      "6\t\t196\t\t1.4674\t\t0.4653\t\t0.6051\t\t79.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1240:\n",
      "Process Process-1236:\n",
      "Process Process-1234:\n",
      "Process Process-1233:\n",
      "Process Process-1235:\n",
      "Process Process-1237:\n",
      "Process Process-1239:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-1238:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 5515) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2962\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2963\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2964\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-0717dc927688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtrn_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mval_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7d0ced679dc0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_loader, model, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_python_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_python_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_python_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_python_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7d0ced679dc0>\u001b[0m in \u001b[0;36mto_python_float\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_pdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m                         \u001b[0;31m# drop into debugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36m_showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# try to preserve ordering of tracebacks and print statements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 5515) exited unexpectedly with exit code 1."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1082, in _validate_lengths\n",
      "    chk = [1 if x is None else x for x in i]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1082, in <listcomp>\n",
      "    chk = [1 if x is None else x for x in i]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = torch.optim.SGD(optim_params, lr=0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.1799\t\t1.6529\t\t1.5806\t\t46.16\n",
      "1\t\t196\t\t0.3402\t\t1.0252\t\t1.2427\t\t57.87\n",
      "2\t\t196\t\t0.5021\t\t0.7953\t\t1.0173\t\t67.06\n",
      "3\t\t196\t\t0.6651\t\t0.6775\t\t1.133\t\t64.4\n",
      "4\t\t196\t\t0.828\t\t0.6355\t\t1.2792\t\t57.2\n",
      "5\t\t196\t\t0.993\t\t0.6217\t\t0.7208\t\t75.02\n",
      "6\t\t196\t\t1.1539\t\t0.6175\t\t0.9251\t\t71.35\n",
      "7\t\t196\t\t1.3183\t\t0.644\t\t1.6398\t\t55.06\n",
      "8\t\t196\t\t1.4817\t\t0.683\t\t1.6067\t\t56.29\n",
      "9\t\t196\t\t1.6452\t\t0.7297\t\t1.0064\t\t66.64\n",
      "10\t\t196\t\t1.8063\t\t0.7822\t\t1.2154\t\t58.1\n",
      "11\t\t196\t\t1.9661\t\t0.8309\t\t2.1561\t\t45.02\n",
      "12\t\t196\t\t2.1274\t\t0.8783\t\t1.6358\t\t48.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-213:\n",
      "Process Process-214:\n",
      "Process Process-216:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-210:\n",
      "Process Process-211:\n",
      "Process Process-215:\n",
      "Process Process-212:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-209:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1446, in pad\n",
      "    newmat = _pad_ref(newmat, (pad_before, pad_after), method, axis)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 83, in to_tensor\n",
      "    return img.float().div(255)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1446, in pad\n",
      "    newmat = _pad_ref(newmat, (pad_before, pad_after), method, axis)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 819, in _pad_ref\n",
      "    start = arr.shape[axis] - pad_amt[1] - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-3605d70d6d69>\", line 43, in <module>\n",
      "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
      "  File \"<ipython-input-8-7d0ced679dc0>\", line 29, in train\n",
      "    output = model(input)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-5-08c899b22ea2>\", line 61, in forward\n",
      "    x = self.layers(x)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-5-08c899b22ea2>\", line 23, in forward\n",
      "    out = self.conv2(F.relu(self.bn2(out)))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 6370) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 838, in _pad_ref\n",
      "    return np.concatenate((ref_chunk1, arr, ref_chunk2), axis=axis)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.1, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.2574\t\t2.0941\t\t1.6994\t\t37.41\n",
      "1\t\t196\t\t0.4985\t\t1.5059\t\t1.3106\t\t52.06\n",
      "2\t\t196\t\t0.7441\t\t1.2128\t\t1.0713\t\t61.56\n",
      "3\t\t196\t\t0.9884\t\t1.0105\t\t0.9797\t\t65.11\n",
      "4\t\t196\t\t1.2306\t\t0.8554\t\t0.8806\t\t69.48\n",
      "5\t\t196\t\t1.4749\t\t0.7441\t\t0.8309\t\t71.5\n",
      "6\t\t196\t\t1.7182\t\t0.6497\t\t0.6912\t\t76.3\n",
      "7\t\t196\t\t1.9626\t\t0.5838\t\t0.8357\t\t73.27\n",
      "8\t\t196\t\t2.2055\t\t0.538\t\t0.6456\t\t78.43\n",
      "9\t\t196\t\t2.4498\t\t0.501\t\t0.6228\t\t78.89\n",
      "10\t\t196\t\t2.6932\t\t0.4629\t\t0.5708\t\t80.92\n",
      "11\t\t196\t\t2.9372\t\t0.4447\t\t0.6431\t\t78.99\n",
      "12\t\t196\t\t3.1781\t\t0.4206\t\t0.4864\t\t83.3\n",
      "13\t\t196\t\t3.4236\t\t0.4015\t\t0.506\t\t82.41\n",
      "14\t\t196\t\t3.6691\t\t0.3848\t\t0.4688\t\t84.49\n",
      "15\t\t196\t\t3.9126\t\t0.3677\t\t0.4915\t\t83.51\n",
      "16\t\t196\t\t4.1571\t\t0.3352\t\t0.4642\t\t84.07\n",
      "17\t\t196\t\t4.4007\t\t0.3009\t\t0.4463\t\t85.32\n",
      "18\t\t196\t\t4.6454\t\t0.2767\t\t0.3799\t\t87.19\n",
      "19\t\t196\t\t4.8882\t\t0.2508\t\t0.3715\t\t87.95\n",
      "20\t\t196\t\t5.134\t\t0.2279\t\t0.3346\t\t88.7\n",
      "21\t\t196\t\t5.3773\t\t0.2045\t\t0.3094\t\t89.55\n",
      "22\t\t196\t\t5.6216\t\t0.1842\t\t0.3149\t\t89.72\n",
      "23\t\t196\t\t5.8661\t\t0.1662\t\t0.3419\t\t89.11\n",
      "24\t\t196\t\t6.1126\t\t0.1458\t\t0.3011\t\t90.49\n",
      "25\t\t196\t\t6.3596\t\t0.1244\t\t0.2878\t\t90.94\n",
      "26\t\t196\t\t6.6051\t\t0.107\t\t0.3095\t\t90.64\n",
      "27\t\t196\t\t6.8508\t\t0.0865\t\t0.2749\t\t91.83\n",
      "28\t\t196\t\t7.0962\t\t0.0725\t\t0.2719\t\t92.06\n",
      "29\t\t196\t\t7.3424\t\t0.0597\t\t0.261\t\t92.54\n",
      "30\t\t196\t\t7.5859\t\t0.0478\t\t0.264\t\t92.67\n",
      "31\t\t196\t\t7.8313\t\t0.0455\t\t0.2681\t\t92.52\n",
      "32\t\t196\t\t8.0787\t\t0.0418\t\t0.2649\t\t92.7\n",
      "33\t\t196\t\t8.3221\t\t0.0398\t\t0.2646\t\t92.55\n",
      "34\t\t196\t\t8.5677\t\t0.0364\t\t0.266\t\t92.55\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.01, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.2456\t\t1.877\t\t1.5124\t\t44.97\n",
      "1\t\t196\t\t0.4912\t\t1.2414\t\t1.2029\t\t57.96\n",
      "2\t\t196\t\t0.736\t\t0.9539\t\t1.0196\t\t65.09\n",
      "3\t\t196\t\t0.9795\t\t0.7618\t\t0.7803\t\t73.53\n",
      "4\t\t196\t\t1.2221\t\t0.6561\t\t0.8809\t\t71.3\n",
      "5\t\t196\t\t1.4669\t\t0.5838\t\t0.8586\t\t70.75\n",
      "6\t\t196\t\t1.7135\t\t0.5367\t\t0.694\t\t76.11\n",
      "7\t\t196\t\t1.956\t\t0.509\t\t0.9822\t\t69.12\n",
      "8\t\t196\t\t2.1984\t\t0.485\t\t0.6546\t\t77.93\n",
      "9\t\t196\t\t2.4431\t\t0.4718\t\t0.7213\t\t76.77\n",
      "10\t\t196\t\t2.6843\t\t0.461\t\t0.6415\t\t78.16\n",
      "11\t\t196\t\t2.9286\t\t0.4541\t\t1.7203\t\t57.35\n",
      "12\t\t196\t\t3.1719\t\t0.449\t\t0.661\t\t77.46\n",
      "13\t\t196\t\t3.4152\t\t0.4511\t\t0.7297\t\t75.95\n",
      "14\t\t196\t\t3.6622\t\t0.4556\t\t0.7215\t\t76.4\n",
      "15\t\t196\t\t3.9107\t\t0.4606\t\t0.6309\t\t79.5\n",
      "16\t\t196\t\t4.156\t\t0.4285\t\t0.6114\t\t79.41\n",
      "17\t\t196\t\t4.4021\t\t0.4045\t\t0.5515\t\t81.69\n",
      "18\t\t196\t\t4.6484\t\t0.3771\t\t0.474\t\t83.63\n",
      "19\t\t196\t\t4.8921\t\t0.3539\t\t0.4681\t\t84.13\n",
      "20\t\t196\t\t5.1364\t\t0.3297\t\t0.5628\t\t81.93\n",
      "21\t\t196\t\t5.3851\t\t0.3056\t\t0.3599\t\t87.71\n",
      "22\t\t196\t\t5.6311\t\t0.2772\t\t0.3563\t\t88.17\n",
      "23\t\t196\t\t5.874\t\t0.2505\t\t0.3595\t\t87.7\n",
      "24\t\t196\t\t6.1207\t\t0.2246\t\t0.3229\t\t89.24\n",
      "25\t\t196\t\t6.3648\t\t0.197\t\t0.3199\t\t89.21\n",
      "26\t\t196\t\t6.6105\t\t0.1689\t\t0.2897\t\t90.72\n",
      "27\t\t196\t\t6.8535\t\t0.1407\t\t0.2769\t\t91.02\n",
      "28\t\t196\t\t7.0987\t\t0.1144\t\t0.2619\t\t92.07\n",
      "29\t\t196\t\t7.344\t\t0.0869\t\t0.2393\t\t92.66\n",
      "30\t\t196\t\t7.5895\t\t0.0637\t\t0.2423\t\t92.73\n",
      "31\t\t196\t\t7.8354\t\t0.062\t\t0.2346\t\t93.14\n",
      "32\t\t196\t\t8.0795\t\t0.0551\t\t0.2335\t\t92.95\n",
      "33\t\t196\t\t8.3239\t\t0.0507\t\t0.2317\t\t93.13\n",
      "34\t\t196\t\t8.5685\t\t0.0449\t\t0.2321\t\t93.1\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.03, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t98\t\t0.2345\t\t1.8791\t\t1.4283\t\t47.64\n",
      "1\t\t98\t\t0.4587\t\t1.2298\t\t1.171\t\t57.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f47f27e2378>\n",
      "Process Process-1395:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/weakref.py\", line 109, in remove\n",
      "Process Process-1396:\n",
      "Process Process-1399:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1397:\n",
      "Process Process-1400:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-1398:\n",
      "Traceback (most recent call last):\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f47f27e2378>\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = Image.fromarray(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2450, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2403, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/weakref.py\", line 109, in remove\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2336, in frombytes\n",
      "    im.frombytes(data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1297, in pad\n",
      "    if not np.asarray(pad_width).dtype.kind == 'i':\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2450, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2403, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 81, in to_tensor\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2336, in frombytes\n",
      "    im.frombytes(data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 783, in frombytes\n",
      "    d = _getdecoder(self.mode, decoder_name, args)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 435, in _getdecoder\n",
      "    decoder = getattr(core, decoder_name + \"_decoder\")\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/numeric.py\", line 492, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1446, in pad\n",
      "    newmat = _pad_ref(newmat, (pad_before, pad_after), method, axis)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 2, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 797, in _pad_ref\n",
      "    for (i, x) in enumerate(arr.shape))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 797, in <genexpr>\n",
      "    for (i, x) in enumerate(arr.shape))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1080, in _validate_lengths\n",
      "    normshp = _normalize_shape(narray, number_elements)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-178544193674>\", line 43, in <module>\n",
      "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
      "  File \"<ipython-input-8-7d0ced679dc0>\", line 21, in train\n",
      "    for i,(input,target) in enumerate(trn_loader):\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 66, in __iter__\n",
      "    self.preload()\n",
      "  File \"<ipython-input-6-91dc9b208998>\", line 54, in preload\n",
      "    self.next_input, self.next_target = next(self.loaditer)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 280, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 259, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 10171) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 989, in _normalize_shape\n",
      "    def _normalize_shape(ndarray, shape, cast_to_int=True):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = LARS(optim_params, lr=0, nesterov=True, eta=0.02, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = LARS(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=[(0,4e-1,15),(4e-1,2e-2,15),(2e-2,0,5)])\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, 512, 512)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
