{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LARC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bd9f237d2ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlarc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLARC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LARC'"
     ]
    }
   ],
   "source": [
    "from larc import LARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse, os, shutil, time, warnings\n",
    "\n",
    "from fp16util import *\n",
    "from resnet import *\n",
    "from PIL import Image\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(), help='Directory to save logs and models.')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--phases', default='[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]', type=str,\n",
    "                    help='Should be a string formatted like this: [(start_lr,end_lr,num_epochs),(phase2...)]')\n",
    "    parser.add_argument('--verbose', action='store_true', help='Verbose logging')\n",
    "#     parser.add_argument('--init-bn0', action='store_true', help='Intialize running batch norm mean to 0')\n",
    "    parser.add_argument('--print-freq', '-p', default=200, type=int,\n",
    "                        metavar='N', help='print every this many steps (default: 5)')\n",
    "#     parser.add_argument('--no-bn-wd', action='store_true', help='Remove batch norm from weight decay')\n",
    "    parser.add_argument('--full-precision', action='store_true', help='Run model full precision mode. Default fp16')\n",
    "    parser.add_argument('--loss-scale', type=float, default=512,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--world-size', default=-1, type=int, \n",
    "                        help='total number of processes (machines*gpus)')\n",
    "    parser.add_argument('--scale-lr', type=float, default=1, help='You should learning rate propotionally to world size')\n",
    "    parser.add_argument('--dist-url', default='env://', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    str(Path.home()/'data/cifar10/'),\n",
    "    '--phases', '[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]',\n",
    "#     '--phases', '[(0,2e-1,16),(2e-1,1e-2,16),(1e-2,0,5)]'\n",
    "#     '--full-precision'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "args = get_parser().parse_args(args_input)\n",
    "if args.full_precision: args.loss_scale = 1\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "class PreActBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size, bs, val_bs=None):\n",
    "    os.makedirs(data_path,exist_ok=True)\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.24703,0.24349,0.26159))]\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=(args.local_rank==0), transform=train_tfms)\n",
    "    val_dataset  = datasets.CIFAR10(root=data_path, train=False, download=(args.local_rank==0), transform=val_tfms)\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "    # val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None)\n",
    "    val_sampler = None\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=val_sampler)\n",
    "    \n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler():\n",
    "    def __init__(self, optimizer, phases=[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_lr = None\n",
    "        self.phases = phases\n",
    "        self.tot_epochs = sum([p[2] for p in phases])\n",
    "\n",
    "    def linear_lr(self, start_lr, end_lr, epoch_curr, batch_curr, epoch_tot, batch_tot):\n",
    "        if args.scale_lr != 1:\n",
    "            start_lr *= args.scale_lr\n",
    "            end_lr *= args.scale_lr\n",
    "        step_tot = epoch_tot * batch_tot\n",
    "        step_curr = epoch_curr * batch_tot + batch_curr\n",
    "        step_size = (end_lr - start_lr)/step_tot\n",
    "        return start_lr + step_curr * step_size\n",
    "    \n",
    "    def get_current_phase(self, epoch):\n",
    "        epoch_accum = 0\n",
    "        for phase in self.phases:\n",
    "            start_lr,end_lr,num_epochs = phase\n",
    "            if epoch <= epoch_accum+num_epochs: return start_lr, end_lr, num_epochs, epoch - epoch_accum\n",
    "            epoch_accum += num_epochs\n",
    "        raise Exception('Epoch out of range')\n",
    "            \n",
    "    def get_lr(self, epoch, batch_curr, batch_tot):\n",
    "        start_lr, end_lr, num_epochs, relative_epoch = self.get_current_phase(epoch)\n",
    "        return self.linear_lr(start_lr, end_lr, relative_epoch, batch_curr, num_epochs, batch_tot)\n",
    "\n",
    "    def update_lr(self, epoch, batch_num, batch_tot):\n",
    "        lr = self.get_lr(epoch, batch_num, batch_tot)\n",
    "        if args.verbose and (self.current_lr != lr) and ((batch_num == 1) or (batch_num == batch_tot)): \n",
    "            print(f'Changing LR from {self.current_lr} to {lr}')\n",
    "\n",
    "        self.current_lr = lr\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr_old = param_group['lr'] or lr\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if isinstance(t, float): return t\n",
    "    if isinstance(t, int): return t\n",
    "    if hasattr(t, 'item'): return t.item()\n",
    "    else: return t[0]\n",
    "\n",
    "def train(trn_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    st = time.time()\n",
    "    trn_len = len(trn_loader)\n",
    "\n",
    "    # print('Begin training loop:', st)\n",
    "    for i,(input,target) in enumerate(trn_loader):\n",
    "        batch_size = input.size(0)\n",
    "        batch_num = i+1\n",
    "        \n",
    "        # measure data loading time\n",
    "        scheduler.update_lr(epoch, i+1, trn_len)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.distributed:\n",
    "            # Must keep track of global batch size, since not all machines are guaranteed equal batches at the end of an epoch\n",
    "            corr1 = correct(output.data, target)[0]\n",
    "            metrics = torch.tensor([batch_size, loss, corr1]).float().cuda()\n",
    "            batch_total, reduced_loss, corr1 = sum_tensor(metrics)\n",
    "            reduced_loss = reduced_loss/dist.get_world_size()\n",
    "            prec1 = corr1*(100.0/batch_total)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "            batch_total = input.size(0)\n",
    "            prec1 = accuracy(output.data, target)[0] # measure accuracy and record loss\n",
    "        losses.update(to_python_float(reduced_loss), to_python_float(batch_total))\n",
    "        top1.update(to_python_float(prec1), to_python_float(batch_total))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        if args.full_precision:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            model_grads_to_master_grads(model_params, master_params)\n",
    "            for param in master_params:\n",
    "                param.grad.data = param.grad.data/args.loss_scale\n",
    "            optimizer.step()\n",
    "            master_params_to_model_params(model_params, master_params)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==trn_len)\n",
    "        if should_print: log_batch(epoch, batch_num, trn_len, batch_time, losses, top1)\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_len = len(val_loader)\n",
    "\n",
    "    for i,(input,target) in enumerate(val_loader):\n",
    "        batch_num = i+1\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target).data\n",
    "        batch_total = input.size(0)\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "            \n",
    "        losses.update(to_python_float(loss), batch_total)\n",
    "        top1.update(to_python_float(prec1), batch_total)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==val_len)\n",
    "        if should_print: log_batch(epoch, batch_num, val_len, batch_time, losses, top1)\n",
    "            \n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "def log_batch(epoch, batch_num, batch_len, batch_time, loss, top1):\n",
    "    if args.local_rank==0 and args.verbose:\n",
    "        output = ('Epoch: [{0}][{1}/{2}]\\t' \\\n",
    "                + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})').format(\n",
    "                epoch, batch_num, batch_len, batch_time=batch_time, loss=loss, top1=top1)\n",
    "        print(output)\n",
    "        with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "            f.write(output + '\\n')\n",
    "            \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = self.avg = self.sum = self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    corrrect_ks = correct(output, target, topk)\n",
    "    batch_size = target.size(0)\n",
    "    return [correct_k.float().mul_(100.0 / batch_size) for correct_k in corrrect_ks]\n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sum_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    return rt\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out batch norm parameters and remove them from weight decay - gets us higher accuracy 93.2 -> 93.48\n",
    "# https://arxiv.org/pdf/1807.11205.pdf\n",
    "def bnwd_optim_params(model, model_params, master_params):\n",
    "    bn_params, remaining_params = split_bn_params(model, model_params, master_params)\n",
    "    return [{'params':bn_params,'weight_decay':0}, {'params':remaining_params}]\n",
    "\n",
    "\n",
    "def split_bn_params(model, model_params, master_params):\n",
    "    def get_bn_params(module):\n",
    "        if isinstance(module, torch.nn.modules.batchnorm._BatchNorm): return module.parameters()\n",
    "        accum = set()\n",
    "        for child in module.children(): [accum.add(p) for p in get_bn_params(child)]\n",
    "        return accum\n",
    "    \n",
    "    mod_bn_params = get_bn_params(model)\n",
    "    zipped_params = list(zip(model_params, master_params))\n",
    "\n",
    "    mas_bn_params = [p_mast for p_mod,p_mast in zipped_params if p_mod in mod_bn_params]\n",
    "    mas_rem_params = [p_mast for p_mod,p_mast in zipped_params if p_mod not in mod_bn_params]\n",
    "    return mas_bn_params, mas_rem_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class LARC(object):\n",
    "    \"\"\"\n",
    "    :class:`LARC` is a pytorch implementation of both the scaling and clipping varients of LARC,\n",
    "    in which the ratio between gradient and parameter magnitudes is used to calculate an adaptive \n",
    "    local learning rate for each individual parameter. The algorithm is designed to improve\n",
    "    convergence of large batch training.\n",
    "     \n",
    "    See https://arxiv.org/abs/1708.03888 for calculation of the local learning rate.\n",
    "\n",
    "    In practice it modifies the gradients of parameters as a proxy for modifying the learning rate\n",
    "    of the parameters. This design allows it to be used as a wrapper around any torch.optim Optimizer.\n",
    "\n",
    "    ```\n",
    "    model = ...\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=...)\n",
    "    optim = LARC(optim)\n",
    "    ```\n",
    "\n",
    "    It can even be used in conjunction with apex.fp16_utils.FP16_optimizer.\n",
    "\n",
    "    ```\n",
    "    model = ...\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=...)\n",
    "    optim = LARC(optim)\n",
    "    optim = apex.fp16_utils.FP16_Optimizer(optim)\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        optimizer: Pytorch optimizer to wrap and modify learning rate for.\n",
    "        trust_coefficient: Trust coefficient for calculating the lr. See https://arxiv.org/abs/1708.03888\n",
    "        clip: Decides between clipping or scaling mode of LARC. If `clip=True` the learning rate is set to `min(optimizer_lr, local_lr)` for each parameter. If `clip=False` the learning rate is set to `local_lr*optimizer_lr`.\n",
    "        eps: epsilon kludge to help with numerical stability while calculating adaptive_lr\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, trust_coefficient=0.02, clip=True, eps=1e-8):\n",
    "        self.param_groups = optimizer.param_groups\n",
    "        self.optim = optimizer\n",
    "        self.trust_coefficient = trust_coefficient\n",
    "        self.eps = eps\n",
    "        self.clip = clip\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self.optim.__getstate__()\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.optim.__setstate__(state)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.optim.__repr__()\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.optim.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.optim.load_state_dict(state_dict)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optim.zero_grad()\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        self.optim.add_param_group( param_group)\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            weight_decays = []\n",
    "            for group in self.optim.param_groups:\n",
    "                # absorb weight decay control from optimizer\n",
    "                weight_decay = group['weight_decay'] if 'weight_decay' in group else 0\n",
    "                weight_decays.append(weight_decay)\n",
    "                group['weight_decay'] = 0\n",
    "                for p in group['params']:\n",
    "                    if p.grad is None:\n",
    "                        continue\n",
    "                    param_norm = torch.norm(p.data)\n",
    "                    grad_norm = torch.norm(p.grad.data)\n",
    "\n",
    "                    if param_norm != 0 and grad_norm != 0:\n",
    "                        # calculate adaptive lr + weight decay\n",
    "                        adaptive_lr = self.trust_coefficient * (param_norm) / (grad_norm + param_norm * weight_decay + self.eps)\n",
    "\n",
    "                        # clip learning rate for LARC\n",
    "                        if self.clip:\n",
    "                            # calculation of adaptive_lr so that when multiplied by lr it equals `min(adaptive_lr, lr)`\n",
    "                            adaptive_lr = min(adaptive_lr/group['lr'], 1)\n",
    "\n",
    "                        p.grad.data += weight_decay * p.data\n",
    "                        p.grad.data *= adaptive_lr\n",
    "\n",
    "        self.optim.step()\n",
    "        # return weight decay control to optimizer\n",
    "        for i, group in enumerate(self.optim.param_groups):\n",
    "            group['weight_decay'] = weight_decays[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, full_precision=True, local_rank=0, loss_scale=1, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir=PosixPath('/home/paperspace/cluster/pytorch-cifar'), scale_lr=1, verbose=False, weight_decay=0.0005, workers=8, world_size=-1)\n",
      "\n",
      "\n",
      "\n",
      "epoch\t\tnum_batch\ttime (min)\ttrn_loss\tval_loss\taccuracy\n",
      "0\t\t196\t\t0.2739\t\t1.7352\t\t1.5278\t\t45.68\n",
      "1\t\t196\t\t0.5297\t\t1.0237\t\t1.1522\t\t59.79\n",
      "2\t\t196\t\t0.7912\t\t0.759\t\t1.3181\t\t61.54\n",
      "3\t\t196\t\t1.0487\t\t0.6381\t\t0.8603\t\t72.04\n",
      "4\t\t196\t\t1.3098\t\t0.5644\t\t0.8394\t\t72.05\n",
      "5\t\t196\t\t1.5688\t\t0.5106\t\t1.1195\t\t66.94\n",
      "6\t\t196\t\t1.8305\t\t0.4702\t\t0.8861\t\t72.31\n",
      "7\t\t196\t\t2.091\t\t0.4376\t\t0.6553\t\t78.23\n",
      "8\t\t196\t\t2.3504\t\t0.4114\t\t0.7458\t\t76.33\n",
      "9\t\t196\t\t2.6097\t\t0.3977\t\t0.5154\t\t82.34\n",
      "10\t\t196\t\t2.873\t\t0.3854\t\t0.5873\t\t80.18\n",
      "11\t\t196\t\t3.1336\t\t0.3843\t\t0.8197\t\t73.21\n",
      "12\t\t196\t\t3.3942\t\t0.3815\t\t0.8105\t\t75.85\n",
      "13\t\t196\t\t3.6541\t\t0.3847\t\t0.6508\t\t76.72\n",
      "14\t\t196\t\t3.9126\t\t0.3853\t\t0.746\t\t75.14\n",
      "15\t\t196\t\t4.1726\t\t0.3857\t\t0.5411\t\t82.48\n",
      "16\t\t196\t\t4.4284\t\t0.3471\t\t0.8097\t\t74.74\n",
      "17\t\t196\t\t4.6906\t\t0.3303\t\t0.5605\t\t81.97\n",
      "18\t\t196\t\t4.9511\t\t0.3058\t\t0.6352\t\t80.19\n",
      "19\t\t196\t\t5.2138\t\t0.2881\t\t0.585\t\t80.74\n",
      "20\t\t196\t\t5.4722\t\t0.2716\t\t0.4821\t\t83.89\n",
      "21\t\t196\t\t5.7336\t\t0.2557\t\t0.4696\t\t84.91\n",
      "22\t\t196\t\t5.9916\t\t0.2325\t\t0.4005\t\t87.06\n",
      "23\t\t196\t\t6.2533\t\t0.2147\t\t0.3304\t\t88.98\n",
      "24\t\t196\t\t6.5159\t\t0.1914\t\t0.3522\t\t88.37\n",
      "25\t\t196\t\t6.777\t\t0.1661\t\t0.3428\t\t88.3\n",
      "26\t\t196\t\t7.0377\t\t0.138\t\t0.273\t\t90.84\n",
      "27\t\t196\t\t7.2977\t\t0.116\t\t0.2358\t\t92.29\n",
      "28\t\t196\t\t7.5575\t\t0.0856\t\t0.2378\t\t92.5\n",
      "29\t\t196\t\t7.8172\t\t0.0593\t\t0.2083\t\t93.58\n",
      "30\t\t196\t\t8.0764\t\t2.6934\t\t69809.77\t\t10.0\n",
      "31\t\t196\t\t8.3317\t\t12.9655\t\t3.5247\t\t21.1\n",
      "32\t\t196\t\t8.5897\t\t2.7083\t\t2.3702\t\t26.58\n",
      "33\t\t196\t\t8.8458\t\t2.303\t\t2.0942\t\t29.84\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 3: divide by zero at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCTensorMathPairwise.cu:88",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fa5517119b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loading start to after everything is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtrn_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mval_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7d0ced679dc0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_loader, model, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7d0c5618bf04>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                             \u001b[0;31m# calculation of adaptive_lr so that when multiplied by lr it equals `min(adaptive_lr, lr)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                             \u001b[0madaptive_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madaptive_lr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 3: divide by zero at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCTensorMathPairwise.cu:88"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "if not args.full_precision: model = network_to_half(model)\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "# TESTING\n",
    "args.full_precision = True\n",
    "args.loss_scale = 1\n",
    "\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help accuracy\n",
    "global model_params, master_params\n",
    "if args.full_precision: model_params = master_params = model.parameters()\n",
    "else: model_params, master_params = prep_param_lists(model)\n",
    "\n",
    "# optim_params = bnwd_optim_params(model, model_params, master_params)\n",
    "optim_params = master_params\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = F.cross_entropy\n",
    "optimizer = torch.optim.SGD(optim_params, lr=0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "optimizer = LARC(optimizer)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(args.data, sz, args.batch_size, args.batch_size*2)\n",
    "\n",
    "print(args)\n",
    "print('\\n\\n')\n",
    "print(\"epoch\\t\\tnum_batch\\ttime (min)\\ttrn_loss\\tval_loss\\taccuracy\")\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    trn_top1, trn_loss = train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    val_top1, val_loss = validate(val_loader, model, criterion, epoch, start_time)\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    minutes = float(time_diff.total_seconds() / 60.0)\n",
    "    # epoch   time   trn_loss   val_loss   accuracy     \n",
    "    metrics = [str(round(i, 4)) for i in [epoch, len(trn_loader), minutes, trn_loss, val_loss, val_top1]]\n",
    "    print('\\t\\t'.join(metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
